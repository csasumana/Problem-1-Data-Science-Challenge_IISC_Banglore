# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13bUUQ-Zddwlp69plk6gBcYfNiMgL-Lm1
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('p1_movie_metadata.csv') #Reading CSV file into dataframe
df

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt   #importing the libraries

# Scatter plot between director's name and title year
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x='director_name', y='title_year')
plt.xticks(rotation=90)  # Rotating  x-axis labels for better readability
plt.title("Scatter Plot: Director's Name vs. title Year")
plt.xlabel("Director's Name")
plt.ylabel("Title Year")
plt.show()

# Box plot of movie durations by director's name
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x='director_name', y='duration')
plt.xticks(rotation=90)  # Rotating x-axis labels for better readability
plt.title("Box Plot: Movie Durations by Director's Name")
plt.xlabel("Director's Name")
plt.ylabel("Duration")
plt.show()

# Histogram of movie genres
plt.figure(figsize=(10, 6))
sns.histplot(data=df, x='genres', bins=20)
plt.xticks(rotation=90)  # Rotating x-axis labels for better readability
plt.title("Histogram: Movie Genres")
plt.xlabel("Genres")
plt.ylabel("Frequency")
plt.show()

#correlation matrix

numeric_columns = df.select_dtypes(include=['number']).columns
correlation_matrix = df[numeric_columns].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title("Correlation Matrix")
plt.show()

print(correlation_matrix)  #correlation matrix wrt every feature

# Checking for missing values in dataframe
missing_values = df.isnull().sum()

# Printing number of missing values of each column
print(missing_values)

print(df.columns)

# Grouping the data by director so we can add new features which help in prediction
director_groups = df.groupby('director_name')

# Calculating average release year and IMDB score for each director
avg_release_year = director_groups['title_year'].mean()
avg_imdb_score = director_groups['imdb_score'].mean()

# Counting the occurrences of each genre for each director
genre_counts = director_groups['genres'].apply(lambda x: pd.Series(x.str.split('|').sum()).value_counts())

# Displaying the results
print("Average Release Year by Director:")
print(avg_release_year)

print("\nAverage IMDB Score by Director:")
print(avg_imdb_score)

# Normalizing genre counts to get proportions
genre_proportions = genre_counts.div(genre_counts.sum(axis=0), axis=0)
print("\nProportion of Movies in Each Genre by Director:")
print(genre_proportions)

df.drop(columns=['actor_3_facebook_likes','color','movie_imdb_link','actor_2_name', 'cast_total_facebook_likes','actor_3_name','facenumber_in_poster','actor_2_facebook_likes'], inplace=True)

# Checking for missing values
missing_values = df.isnull().sum()

# Printing number of missing values for each column
print(missing_values)

import pandas as pd

#to remove the data which dont have director name
missing_directors = df[df['director_name'].isnull()]
df_cleaned = df.dropna(subset=['director_name'])

# Calculating  mean duration
mean_duration = df_cleaned['duration'].mean()

# Filling missing values with the mean
df_cleaned['duration'].fillna(mean_duration, inplace=True)

df_cleaned.drop(columns=['actor_1_facebook_likes'], inplace=True)

#whether to drop gross or not
correlation = df['gross'].corr(df['title_year'])
correlation

#droping columns that are not useful
df_cleaned.drop(columns=['gross','language','country'], inplace=True)

#to remove the data which dont have title year
df_cleaned1 = df_cleaned.dropna(subset=['title_year'])

# Calculating mean duration
mean_budget = df_cleaned1['budget'].mean()

# Filling the missing values with  mean
df_cleaned1['budget'].fillna(mean_budget, inplace=True)

import numpy as np

#to create a dictionary with new features and merge them with original dataframe
avg_imdb_scores_dict = dict(zip(avg_imdb_score.keys(), avg_imdb_score.tolist()))



avg_release_year_dict = dict(zip(avg_release_year.keys(), avg_release_year.tolist()))


genre_proportions_dict = dict(zip(genre_proportions.keys(), genre_proportions.tolist()))

scaled_genre_proportions = {genre: proportion * 1000 for genre, proportion in genre_proportions.items()}

# Create a dictionary with all the calculated features
director_features = {
    'director_name': list(avg_imdb_score.keys()),
    'Avg IMDb Score': list(avg_imdb_scores_dict.values()),
    'Avg Release Year': list(avg_release_year_dict.values()),
    'genre_proportions': list(genre_proportions_dict.values()),
}


filtered_genre_proportions = [genre_proportions[director_name] for director_name in avg_imdb_score.keys()]

# Updating director_features dictionary
director_features['genre_proportions'] = filtered_genre_proportions

# Creating DataFrame
director_features_df = pd.DataFrame(director_features)

# Merging the original DataFrame with the new_features_df based on the director's name
merged_df = pd.merge(df_cleaned1, director_features_df, on='director_name', how='left')

# Displaying the merged DataFrame
print(merged_df)

# Calculating mean duration
mean_num_critic_for_reviews = merged_df['num_critic_for_reviews'].mean()

# Filling the missing values with  mean
merged_df['num_critic_for_reviews'].fillna(mean_num_critic_for_reviews, inplace=True)


# Calculating the mean duration
mean_num_user_for_reviews = merged_df['num_user_for_reviews'].mean()

# Filling the missing values with mean
merged_df['num_user_for_reviews'].fillna(mean_num_user_for_reviews, inplace=True)

merged_df.drop(columns=['aspect_ratio','plot_keywords','actor_1_name','content_rating'], inplace=True)

# Performing one-hot encoding for the 'genres' column
genres_encoded = merged_df['genres'].str.get_dummies(sep='|')

# Concatenating the one-hot encoded genres with the original DataFrame
df_encoded = pd.concat([merged_df, genres_encoded], axis=1)

# Droping the original 'genres' column
df_encoded.drop(columns=['genres'], inplace=True)

# printing the encoded DataFrame
print(df_encoded.head())

df_encoded.drop(columns=['genre_proportions','movie_title'], inplace=True)

from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()

# Encoding the 'director_name' column and assigning it to a new column named 'director_label_encoded'
df_encoded['director_label_encoded'] = label_encoder.fit_transform(df_encoded['director_name'])

# Now, droping the original 'director_name' column
df_encoded.drop(columns=['director_name'], inplace=True)

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import pandas as pd

from sklearn.model_selection import train_test_split

# Considering these features for regression model(predicting the title_year)
X_regression = df_encoded[['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'num_voted_users',
                   'num_user_for_reviews', 'budget', 'imdb_score', 'movie_facebook_likes',
                   'Avg IMDb Score', 'director_label_encoded','Avg Release Year','Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',
                       'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History',
                       'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi',
                       'Short', 'Sport', 'Thriller', 'War', 'Western']]

# Target variable for regression model
y_regression = df_encoded['title_year']

# Split data for regression model
X_regression_train, X_regression_test, y_regression_train, y_regression_test = train_test_split(
    X_regression, y_regression, test_size=0.2, random_state=35)

# Features for classification model(predicting the genre)
X_classification = df_encoded[['num_critic_for_reviews', 'duration', 'director_facebook_likes', 'num_voted_users',
                       'num_user_for_reviews', 'budget', 'imdb_score', 'movie_facebook_likes',
                       'Avg IMDb Score', 'director_label_encoded',
                       'Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',
                       'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History',
                       'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi',
                       'Short', 'Sport', 'Thriller', 'War', 'Western']]

# Target variables for classification model
y_classification = df_encoded[['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime',
                       'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History',
                       'Horror', 'Music', 'Musical', 'Mystery', 'News', 'Romance', 'Sci-Fi',
                       'Short', 'Sport', 'Thriller', 'War', 'Western']]

# Split data for classification model
X_classification_train, X_classification_test, y_classification_train, y_classification_test = train_test_split(
    X_classification, y_classification, test_size=0.2, random_state=20)

#  Training the model
model = RandomForestRegressor(n_estimators=100, random_state=36)
model.fit(X_regression_train, y_regression_train)

y_regression_pred = model.predict(X_regression_test)

# evaluation for regression:
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Calculate Mean Absolute Error (MAE)
mae_regression = mean_absolute_error(y_regression_test, y_regression_pred)

# Calculate Mean Squared Error (MSE)
mse_regression = mean_squared_error(y_regression_test, y_regression_pred)

# Calculate R-squared (R2)
r2_regression = r2_score(y_regression_test, y_regression_pred)


# Printing the evaluation metrics
print("Mean Absolute Error:", mae_regression)
print("Mean Squared Error:", mse_regression)
print("R-squared:", r2_regression)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Train multi-class classification model for genre prediction
from sklearn.ensemble import RandomForestClassifier
classification_model = RandomForestClassifier(n_estimators=100, random_state=25)
classification_model.fit(X_classification_train, y_classification_train)

# Using the trained model to make predictions on the test set
y_classification_pred = classification_model.predict(X_classification_test)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score

# Accuracy
accuracy = accuracy_score(y_classification_test, y_classification_pred)

# Precision
precision = precision_score(y_classification_test, y_classification_pred, average = 'micro')

# Recall
recall = recall_score(y_classification_test, y_classification_pred, average = 'micro')

# F1-score
f1 = f1_score(y_classification_test, y_classification_pred, average = 'micro')

# Printing the evaluation metrics
print("accuracy:", accuracy)
print("precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)

















































